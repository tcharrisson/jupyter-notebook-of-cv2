{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64a94167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365876ca",
   "metadata": {},
   "source": [
    "im = cv2.imread('dark.png')\n",
    "orig = im.copy()\n",
    "cv2.imshow('image', im)\n",
    "plt.imshow(im)\n",
    "plt.show()\n",
    "\n",
    "tmin = 0.1   # minimum value for t to make J image\n",
    "w = 15       # window size, which determine the corseness of prior images\n",
    "alpha = 0.4  # threshold for transmission correction\n",
    "omega = 0.75 # this is for dark channel prior\n",
    "p = 0.1      # percentage to consider for atmosphere\n",
    "eps = 1e-3   # for J image\n",
    "\n",
    "I = np.asarray(im, dtype=np.float64) # Convert the input to an array.\n",
    "I = I[:, :, :3] / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5d9121",
   "metadata": {},
   "source": [
    "## Obtaining the Bright and Dark channel Prior form the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16d71047",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread('dark.png')\n",
    "orig = im.copy()\n",
    "tmin = 0.1  # minimum value for t to make J image\n",
    "w = 15  # window size, which determine the corseness of prior images\n",
    "alpha = 0.4  # threshold for transmission correction\n",
    "omega = 0.75  # this is for dark channel prior\n",
    "p = 0.1  # percentage to consider for atmosphere\n",
    "eps = 1e-3  # for J image\n",
    "\n",
    "I = np.asarray(im, dtype=np.float64)  # Convert the input to an array.\n",
    "I = I[:, :, :3] / 255  #padding the channels\n",
    "\n",
    "\n",
    "def get_illumination_channel(I, w):\n",
    "    M, N, _ = I.shape\n",
    "    padded = np.pad(I, ((int(w/2), int(w/2)), (int(w/2), int(w/2)), (0, 0)), 'edge')\n",
    "    darkch = np.zeros((M, N))\n",
    "    brightch = np.zeros((M, N))\n",
    "\n",
    "    for i, j in np.ndindex(darkch.shape):\n",
    "        darkch[i, j] = np.min(padded[i:i + w, j:j + w, :])\n",
    "        brightch[i, j] = np.max(padded[i:i + w, j:j + w, :])\n",
    "\n",
    "    return darkch, brightch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06092d87",
   "metadata": {},
   "source": [
    "## Computing Global Atmosphere Lighting from the brightch using top 10% brightest pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73f186a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_atmosphere(I, brightch, p=0.1):\n",
    "    M, N = brightch.shape\n",
    "    flatI = I.reshape(M*N, 3)\n",
    "    flatbright = brightch.ravel()\n",
    "\n",
    "    searchidx = (-flatbright).argsort()[:int(M*N*p)]\n",
    "    A = np.mean(flatI.take(searchidx, axis=0), dtype=np.float64, axis=0)\n",
    "    return A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418794ef",
   "metadata": {},
   "source": [
    "## Finding the Initial Transmission Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "591ddfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_transmission(A, brightch):\n",
    "    A_c = np.max(A)\n",
    "    init_t = (brightch-A_c)/(1.-A_c)\n",
    "    return (init_t - np.min(init_t))/(np.max(init_t) - np.min(init_t))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2658472e",
   "metadata": {},
   "source": [
    "##  Using Dark Channel to Estimate Corrected Transmission Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18be9f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corrected_transmission(I, A, darkch, brightch, init_t, alpha, omega, w):\n",
    "    im3 = np.empty(I.shape, I.dtype);\n",
    "    for ind in range(0, 3):\n",
    "        im3[:, :, ind] = I[:, :, ind] / A[ind]\n",
    "    dark_c, _ = get_illumination_channel(im3, w)\n",
    "    dark_t = 1 - omega*dark_c\n",
    "    corrected_t = init_t\n",
    "    diffch = brightch - darkch\n",
    "\n",
    "    for i in range(diffch.shape[0]):\n",
    "        for j in range(diffch.shape[1]):\n",
    "            if(diffch[i, j] < alpha):\n",
    "                corrected_t[i, j] = dark_t[i, j] * init_t[i, j]\n",
    "\n",
    "    return np.abs(corrected_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29366f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations_with_replacement\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "\n",
    "B, G, R = 0, 1, 2  # index for convenience\n",
    "\n",
    "def boxfilter(I, r):\n",
    "    \"\"\"Fast box filter implementation.\n",
    "    Parameters\n",
    "    ----------\n",
    "    I:  a single channel/gray image data normalized to [0.0, 1.0]\n",
    "    r:  window radius\n",
    "    Return\n",
    "    -----------\n",
    "    The filtered image data.\n",
    "    \"\"\"\n",
    "    M, N = I.shape\n",
    "    dest = np.zeros((M, N))\n",
    "    #print(I)\n",
    "    \n",
    "    # cumulative sum over Y axis (tate-houkou no wa)\n",
    "    sumY = np.cumsum(I, axis=0)\n",
    "    #print('sumY:{}'.format(sumY))\n",
    "    # difference over Y axis\n",
    "    dest[:r + 1] = sumY[r:2*r + 1] # top r+1 lines\n",
    "    dest[r + 1:M - r] = sumY[2*r + 1:] - sumY[:M - 2*r - 1]\n",
    "    #print(sumY[2*r + 1:]) # from 2*r+1 to end lines\n",
    "    #print(sumY[:M - 2*r - 1]) # same lines of above, from start\n",
    "    #tile replicate sumY[-1] and line them up to match the shape of (r, 1)\n",
    "    dest[-r:] = np.tile(sumY[-1], (r, 1)) - sumY[M - 2*r - 1:M - r - 1] # bottom r lines\n",
    "\n",
    "    # cumulative sum over X axis\n",
    "    sumX = np.cumsum(dest, axis=1)\n",
    "    #print('sumX:{}'.format(sumX))\n",
    "    # difference over X axis\n",
    "    dest[:, :r + 1] = sumX[:, r:2*r + 1] # left r+1 columns\n",
    "    dest[:, r + 1:N - r] = sumX[:, 2*r + 1:] - sumX[:, :N - 2*r - 1]\n",
    "    dest[:, -r:] = np.tile(sumX[:, -1][:, None], (1, r)) - sumX[:, N - 2*r - 1:N - r - 1] # right r columns\n",
    "\n",
    "    #print(dest)\n",
    "\n",
    "    return dest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ae32c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guided_filter(I, p, r=15, eps=1e-3):\n",
    "    \"\"\"Refine a filter under the guidance of another (RGB) image.\n",
    "    Parameters\n",
    "    -----------\n",
    "    I:   an M * N * 3 RGB image for guidance.\n",
    "    p:   the M * N filter to be guided. transmission is used for this case.\n",
    "    r:   the radius of the guidance\n",
    "    eps: epsilon for the guided filter\n",
    "    Return\n",
    "    -----------\n",
    "    The guided filter.\n",
    "    \"\"\"\n",
    "    M, N = p.shape\n",
    "    base = boxfilter(np.ones((M, N)), r) # this is needed for regularization\n",
    "    \n",
    "    # each channel of I filtered with the mean filter. this is myu.\n",
    "    means = [boxfilter(I[:, :, i], r) / base for i in range(3)]\n",
    "    \n",
    "    # p filtered with the mean filter\n",
    "    mean_p = boxfilter(p, r) / base\n",
    "\n",
    "    # filter I with p then filter it with the mean filter\n",
    "    means_IP = [boxfilter(I[:, :, i]*p, r) / base for i in range(3)]\n",
    "\n",
    "    # covariance of (I, p) in each local patch\n",
    "    covIP = [means_IP[i] - means[i]*mean_p for i in range(3)]\n",
    "\n",
    "    # variance of I in each local patch: the matrix Sigma in ECCV10 eq.14\n",
    "    var = defaultdict(dict)\n",
    "    for i, j in combinations_with_replacement(range(3), 2):\n",
    "        var[i][j] = boxfilter(I[:, :, i]*I[:, :, j], r) / base - means[i]*means[j]\n",
    "\n",
    "    a = np.zeros((M, N, 3))\n",
    "    for y, x in np.ndindex(M, N):\n",
    "        #         rr, rg, rb\n",
    "        # Sigma = rg, gg, gb\n",
    "        #         rb, gb, bb\n",
    "        Sigma = np.array([[var[B][B][y, x], var[B][G][y, x], var[B][R][y, x]],\n",
    "                          [var[B][G][y, x], var[G][G][y, x], var[G][R][y, x]],\n",
    "                          [var[B][R][y, x], var[G][R][y, x], var[R][R][y, x]]])\n",
    "        cov = np.array([c[y, x] for c in covIP])\n",
    "        a[y, x] = np.dot(cov, inv(Sigma + eps*np.eye(3)))  # eq 14\n",
    "\n",
    "    # ECCV10 eq.15\n",
    "    b = mean_p - a[:, :, R]*means[R] - a[:, :, G]*means[G] - a[:, :, B]*means[B]\n",
    "\n",
    "    # ECCV10 eq.16\n",
    "    q = (boxfilter(a[:, :, R], r)*I[:, :, R] + boxfilter(a[:, :, G], r)*I[:, :, G] + boxfilter(a[:, :, B], r)*I[:, :, B] + boxfilter(b, r)) / base\n",
    "\n",
    "    return q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "491b8e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_image(I, A, refined_t, tmin):\n",
    "    refined_t_broadcasted = np.broadcast_to(refined_t[:, :, None], (refined_t.shape[0], refined_t.shape[1], 3))\n",
    "    J = (I-A) / (np.where(refined_t_broadcasted < tmin, tmin, refined_t_broadcasted)) + A\n",
    "\n",
    "    return (J - np.min(J))/(np.max(J) - np.min(J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07fbe496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dehaze(I, tmin, w, alpha, omega, p, eps, reduce=False):\n",
    "    m, n, _ = I.shape\n",
    "    Idark, Ibright = get_illumination_channel(I, w)\n",
    "    A = get_atmosphere(I, Ibright, p)\n",
    "\n",
    "    init_t = get_initial_transmission(A, Ibright) \n",
    "    if reduce:\n",
    "        init_t = reduce_init_t(init_t)\n",
    "    corrected_t = get_corrected_transmission(I, A, Idark, Ibright, init_t, alpha, omega, w)\n",
    "\n",
    "    normI = (I - I.min()) / (I.max() - I.min())\n",
    "    refined_t = guided_filter(normI, corrected_t, w, eps)\n",
    "    J_refined = get_final_image(I, A, refined_t, tmin)\n",
    "    \n",
    "    enhanced = (J_refined*255).astype(np.uint8)\n",
    "    f_enhanced = cv2.detailEnhance(enhanced, sigma_s=10, sigma_r=0.15)\n",
    "    f_enhanced = cv2.edgePreservingFilter(f_enhanced, flags=1, sigma_s=64, sigma_r=0.2)\n",
    "    return f_enhanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "506b9167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_init_t(init_t):\n",
    "    init_t = (init_t*255).astype(np.uint8)\n",
    "    xp = [0, 32, 255]\n",
    "    fp = [0, 32, 48]\n",
    "    x = np.arange(256)\n",
    "    table = np.interp(x, xp, fp).astype('uint8')\n",
    "    init_t = cv2.LUT(init_t, table)\n",
    "    init_t = init_t.astype(np.float64)/255\n",
    "    return init_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbf2c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread('dark.png')\n",
    "orig = im.copy()\n",
    "\n",
    "tmin = 0.1   # minimum value for t to make J image\n",
    "w = 15       # window size, which determine the corseness of prior images\n",
    "alpha = 0.4  # threshold for transmission correction\n",
    "omega = 0.75 # this is for dark channel prior\n",
    "p = 0.1      # percentage to consider for atmosphere\n",
    "eps = 1e-3   # for J image\n",
    "\n",
    "I = np.asarray(im, dtype=np.float64) # Convert the input to an array.\n",
    "I = I[:, :, :3] / 255\n",
    "\n",
    "f_enhanced = dehaze(I, tmin, w, alpha, omega, p, eps)\n",
    "f_enhanced2 = dehaze(I, tmin, w, alpha, omega, p, eps, True)\n",
    "cv2.imshow('original', orig)\n",
    "cv2.imshow('F_enhanced', f_enhanced)\n",
    "cv2.imshow('F_enhanced2', f_enhanced2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
